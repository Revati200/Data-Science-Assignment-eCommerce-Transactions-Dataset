{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24023418-a10e-4e59-a77c-d930f5afd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a48428-5fce-4c53-8559-9a3bcef6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "customers_df = pd.read_csv('Customers.csv')\n",
    "products_df = pd.read_csv('Products.csv')\n",
    "transactions_df = pd.read_csv('Transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e554f0-f612-4ade-8507-0a278615d8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the first few rows of each dataset\n",
    "print(customers_df.head())\n",
    "print(products_df.head())\n",
    "print(transactions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64fb376a-2915-46f8-8272-88a4868f4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SignupDate to datetime\n",
    "customers_df['SignupDate'] = pd.to_datetime(customers_df['SignupDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07818eba-b68b-4a3f-b7d7-6669c2532355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge customer and transaction data on CustomerID\n",
    "transactions_with_customer = pd.merge(transactions_df, customers_df, on='CustomerID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03f0192-a974-43d5-b7c4-85275898fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with product data on ProductID\n",
    "transactions_with_full_info = pd.merge(transactions_with_customer, products_df, on='ProductID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c82a51eb-6850-4393-9d3f-12bf6dcc5ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue  Price_x     CustomerName         Region SignupDate  \\\n",
      "0      300.68   300.68   Andrea Jenkins         Europe 2022-12-03   \n",
      "1      300.68   300.68  Brittany Harvey           Asia 2024-09-04   \n",
      "2      300.68   300.68  Kathryn Stevens         Europe 2024-04-04   \n",
      "3      601.36   300.68  Travis Campbell  South America 2024-04-11   \n",
      "4      902.04   300.68    Timothy Perez         Europe 2022-03-15   \n",
      "\n",
      "                       ProductName     Category  Price_y  \n",
      "0  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "1  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "2  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "3  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "4  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the combined dataset\n",
    "print(transactions_with_full_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80c6a6ea-da2d-42c5-9739-f0a7536befa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by CustomerID to compute customer-level features\n",
    "customer_features = transactions_with_full_info.groupby('CustomerID').agg(\n",
    "    total_spent=pd.NamedAgg(column='TotalValue', aggfunc='sum'),\n",
    "    num_transactions=pd.NamedAgg(column='TransactionID', aggfunc='nunique'),\n",
    "    num_products=pd.NamedAgg(column='ProductID', aggfunc='nunique'),\n",
    "    avg_transaction_value=pd.NamedAgg(column='TotalValue', aggfunc='mean')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5dfee59-179e-49eb-b381-8c86be2088f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the features with customer data\n",
    "customer_features = pd.merge(customer_features, customers_df[['CustomerID', 'Region']], on='CustomerID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b356d604-5fcb-4164-be74-4307de9e7c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  total_spent  num_transactions  num_products  \\\n",
      "0      C0001      3354.52                 5             5   \n",
      "1      C0002      1862.74                 4             4   \n",
      "2      C0003      2725.38                 4             4   \n",
      "3      C0004      5354.88                 8             8   \n",
      "4      C0005      2034.24                 3             3   \n",
      "\n",
      "   avg_transaction_value         Region  \n",
      "0                670.904  South America  \n",
      "1                465.685           Asia  \n",
      "2                681.345  South America  \n",
      "3                669.360  South America  \n",
      "4                678.080           Asia  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the features\n",
    "print(customer_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4acfe6-3652-41c7-a33f-8efb52c627eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "383addb2-f6aa-4367-b5f3-095674a71c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features for similarity calculation (excluding CustomerID)\n",
    "features = customer_features[['total_spent', 'num_transactions', 'num_products', 'avg_transaction_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72052c53-d8b1-4b6c-8d7a-196ee3aef937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features if needed (you can use StandardScaler from sklearn)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "521313ec-f71f-4ca9-a580-3cdb81cbc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49139e9e-bd69-43e9-ab9d-486ab695173c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerID     C0001     C0002     C0003     C0004     C0005     C0006  \\\n",
      "CustomerID                                                               \n",
      "C0001       1.000000  0.681909  0.137497 -0.000631  0.104379 -0.817502   \n",
      "C0002       0.681909  1.000000  0.726043 -0.649737  0.713370 -0.574811   \n",
      "C0003       0.137497  0.726043  1.000000 -0.990094  0.999224  0.145356   \n",
      "C0004      -0.000631 -0.649737 -0.990094  1.000000 -0.994545 -0.243356   \n",
      "C0005       0.104379  0.713370  0.999224 -0.994545  1.000000  0.162666   \n",
      "\n",
      "CustomerID     C0007     C0008     C0009     C0010  ...     C0191     C0192  \\\n",
      "CustomerID                                          ...                       \n",
      "C0001      -0.333941  0.386237  0.624453  0.709473  ...  0.919641  0.624733   \n",
      "C0002       0.251699 -0.287615  0.995853  0.998487  ...  0.857196  0.994684   \n",
      "C0003       0.847614 -0.845892  0.755674  0.687131  ...  0.287739  0.792995   \n",
      "C0004      -0.892865  0.904547 -0.688581 -0.607304  ... -0.174444 -0.723908   \n",
      "C0005       0.856529 -0.860243  0.745599  0.673804  ...  0.265389  0.781651   \n",
      "\n",
      "CustomerID     C0193     C0194     C0195     C0196     C0197     C0198  \\\n",
      "CustomerID                                                               \n",
      "C0001      -0.250786  0.419163  0.078533 -0.891648  0.186112  0.359169   \n",
      "C0002       0.347354 -0.239990 -0.595834 -0.604817  0.779594  0.904670   \n",
      "C0003       0.897026 -0.828913 -0.975937  0.099661  0.995790  0.941825   \n",
      "C0004      -0.932562  0.890387  0.996839 -0.211301 -0.981563 -0.908311   \n",
      "C0005       0.904113 -0.843402 -0.983129  0.121884  0.994959  0.938235   \n",
      "\n",
      "CustomerID     C0199     C0200  \n",
      "CustomerID                      \n",
      "C0001       0.653288 -0.846661  \n",
      "C0002       0.998585 -0.889077  \n",
      "C0003       0.761586 -0.334939  \n",
      "C0004      -0.688907  0.236094  \n",
      "C0005       0.749583 -0.317883  \n",
      "\n",
      "[5 rows x 199 columns]\n"
     ]
    }
   ],
   "source": [
    "similarity_df = pd.DataFrame(similarity_matrix, index=customer_features['CustomerID'], columns=customer_features['CustomerID'])\n",
    "print(similarity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9358c3fc-6e22-4209-9f83-310cd1ae5829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID Lookalike_1_ID  Lookalike_1_Score Lookalike_2_ID  \\\n",
      "0      C0001          C0137           0.996211          C0152   \n",
      "1      C0002          C0029           0.999535          C0199   \n",
      "2      C0003          C0178           0.999689          C0005   \n",
      "3      C0004          C0021           0.999785          C0075   \n",
      "4      C0005          C0073           0.999667          C0063   \n",
      "\n",
      "   Lookalike_2_Score Lookalike_3_ID  Lookalike_3_Score  \n",
      "0           0.981064          C0056           0.948258  \n",
      "1           0.998585          C0010           0.998487  \n",
      "2           0.999224          C0073           0.998479  \n",
      "3           0.999585          C0067           0.999207  \n",
      "4           0.999401          C0159           0.999295  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to get top N lookalikes\n",
    "def get_top_lookalikes(customer_idx, similarity_matrix, top_n=3):\n",
    "    # Get similarity scores for the given customer index\n",
    "    similarity_scores = similarity_matrix[customer_idx]\n",
    "    \n",
    "    # Sort customers by similarity score in descending order (exclude the customer itself)\n",
    "    sorted_indices = np.argsort(similarity_scores)[::-1][1:top_n+1]  # Exclude the customer itself\n",
    "    \n",
    "    # Extract similarity scores for the top N similar customers\n",
    "    top_scores = similarity_scores[sorted_indices]\n",
    "    \n",
    "    return [(idx, score) for idx, score in zip(sorted_indices, top_scores)]\n",
    "\n",
    "# Create a dictionary for lookalike mapping\n",
    "lookalike_dict = {}\n",
    "\n",
    "# Ensure CustomerID is mapped to its corresponding index\n",
    "customer_id_to_index = {cid: idx for idx, cid in enumerate(customer_features['CustomerID'])}\n",
    "index_to_customer_id = {idx: cid for cid, idx in customer_id_to_index.items()}\n",
    "\n",
    "# Get the top 3 lookalikes for customers from C0001 to C0020\n",
    "for customer_id in customer_features['CustomerID'][:20]:\n",
    "    customer_idx = customer_id_to_index[customer_id]\n",
    "    lookalikes = get_top_lookalikes(customer_idx, similarity_matrix, top_n=3)\n",
    "    \n",
    "    # Convert indices back to CustomerID\n",
    "    lookalike_dict[customer_id] = [(index_to_customer_id[idx], score) for idx, score in lookalikes]\n",
    "\n",
    "# Convert the lookalike dictionary into a DataFrame\n",
    "lookalike_rows = []\n",
    "for cust_id, lookalikes in lookalike_dict.items():\n",
    "    row = {\"CustomerID\": cust_id}\n",
    "    for i, (lookalike_id, score) in enumerate(lookalikes):\n",
    "        row[f\"Lookalike_{i+1}_ID\"] = lookalike_id\n",
    "        row[f\"Lookalike_{i+1}_Score\"] = score\n",
    "    lookalike_rows.append(row)\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_rows)\n",
    "\n",
    "# Save to CSV\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "print(lookalike_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c8414-385c-441f-b598-b3d8864b5d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
